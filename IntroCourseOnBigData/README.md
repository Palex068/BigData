# Вводный курс по Big Data (лекции)

## Содержание

[1. Введение в большие данные](#введение-в-большие-данные)
+ [Введение](#введение)
+ [Термины, используемые в лекции](#термины-используемые-в-лекции)
+ [Что такое Big Data](#что-такое-big-data)
+ [Развитие больших данных](#развитие-больших-данных)
+ [Тренды и ограничения в Big Data](#тренды-и-ограничения-в-big-data)
+ [Распределённые системы](#распределённые-системы)
+ [Распределённое программирование](#распределённое-программирование)
+ [Распределённые файловые системы](#распределённые-файловые-системы)
+ [Системы управления и хранения данных](#системы-управления-и-хранения-данных)
+ [Форматы хранения данных](#форматы-хранения-данных)
+ [Выводы](#выводы)
+ [Что можно почитать ещё?](#что-можно-почитать-ещё)
+ [Вопросы к лекции](#вопросы-к-лекции)
+ [Используемая литература](#используемая-литература)


# Введение в большие данные
# Введение
Этот курс создан для погружения в мир больших данных. В результате следующих трёх уроков мы:
+ расширим свои знания в области Big Data;
+ узнаем, как происходит работа с большими данными и в чём отличие от стандартных подходов;
+ рассмотрим основные инструменты для работы Big Data-специалиста.

К концу курса мы поймём, где и зачем нужна Big Data, какие технологии и навыки нужны для старта карьеры в этой сфере.<br>
На первой лекции познакомимся с понятием «Big Data» и узнаем, где оно применяется. А также рассмотрим базовые концепции и инструменты, которые используются вместе с большими данными.

[Содержание](#содержание)
<hr>

# Термины, используемые в лекции

__База данных (БД)__ — совокупность взаимосвязанных и хранящихся вместе данных, организованных и хранимых специальным образом.

__Система управления базой данных (СУБД)__ — совокупность языковых и программных средств для создания, ведения и совместного использования БД.

__ACID__ — набор свойств транзакций базы данных, призванных гарантировать достоверность данных, несмотря на ошибки и сбои. Аббревиатура от atomicity, consistency, isolation, durability — атомарность, согласованность, изолированность, надёжность.

__Машинное обучение__ — наука о разработке алгоритмов и статистических моделей, которые решают определённые задачи, полагаясь на шаблоны и логические выводы.

__API__ — набор команд, которыми одна компьютерная программа может взаимодействовать с другой.

__CPU-Bound операции__ — операции, которые нагружают вычислительные мощности устройства. CPU-Bound операциям противопоставляются I/O-Bound операции, время выполнения которых в основном регулируется временем выполнения всех операций ввода/вывода.

__Шардирование__ — принцип проектирования базы данных, при котором логически независимые строки таблицы БД хранятся раздельно, заранее сгруппированные в секции, которые размещаются на разных физически и логически независимых серверах.

__ETL__ — процесс извлечения, преобразования и загрузки данных.

__ELT__ — процесс извлечения, загрузки и преобразования данных.

[Содержание](#содержание)
<hr>

# Что такое Big Data

Термин «Big Data» (большие данные) предложил редактор журнала Nature Клиффорд Линч в [спецвыпуске](https://www.nature.com/nature/volumes/455/issues/7209) 2008 года, где говорил о взрывном росте объёмов информации в мире. К большим данным Линч отнёс любые массивы неоднородных данных более 150 Гб в сутки. Однако единого критерия больших данных до сих пор нет.

Обычно выделяют три свойства, характерные для больших данных. Их называют «три V» или VVV:
1. __Volume__ — большой объём. <br>
Ценность таких данных не всегда известна. Это могут быть данные каналов Twitter, данные посещаемости веб-страниц, данные мобильных приложений, сетевой трафик, данные датчиков и прочее.<br>
В некоторых организациях хранятся десятки терабайт данных, в других — сотни петабайт.

2. __Velocity__ — скорость появления и обработки данных. В том числе обработка в реальном времени.
3. __Variety__ — разнообразие типов данных. Неструктурированные и полуструктурированные типы данных, такие как текст, аудио и видео, требуют дополнительной обработки для определения их значения и метаданных.

_Набор признаков volume, velocity, variety выработан в 2001 году вне контекста больших данных, а в связи с ростом популярности концепции центрального хранилища данных для организаций. Отмечалась равнозначность проблематик управления данными по всем трём аспектам._

Часто к трём V добавляют ещё три V:

4. __Veracity__ — достоверность как самого набора данных, так и результатов его анализа;
5. __Variability__ — изменчивость. У потоков данных бывают свои пики и спады под влиянием сезонов или социальных явлений.
6. __Value__ — ценность или значимость. Как и любая информация, большие данные могут быть простыми или сложными для восприятия и анализа. Пример
простых данных — посты в соцсетях, сложных — банковские транзакции.

_Есть множество интерпретаций: с четырьмя V, пятью V, семью V (добавляется визуализация — visualization) и даже с десятью V._ <br>
_Иногда участники рынка интерпретируют некоторые V неодинаково._

Получается, мы имеем что-то объёмное, изменчивое и неструктурированное, и это что-то нужно уметь достаточно быстро обрабатывать, чтобы результатами обработки успели воспользоваться заинтересованные лица. При этом, чем нестабильнее, изменчивее, разнообразнее поток данных, тем сложнее его анализировать.

Понятие «Big Data» конкретно не определено. Одни и те же данные для разных компаний могут быть как большими, так и нет, в зависимости от того, как часто и быстро их нужно обрабатывать.

Можно встретить такое определение: __большие данные__ — это набор данных, размер которых превосходит возможности типичных баз данных (БД) по занесению, хранению, управлению и анализу информации.

Определяющей характеристикой для больших данных часто выступает не только их объём, но и другие категории, существенные для представления о сложности их обработки и анализа.

Типичные примеры больших данных:
+ транзакции,
+ соцсети (сообщения, клики, фото),
+ информация о клиентах (звонки, телеметрия),
+ датчики (интернет вещей),
+ сетевой трафик,
+ научные исследования (Большой адронный коллайдер, телескопы) и так далее.

![001](/IntroCourseOnBigData/Pictures/001_001.PNG)

Год столкновений в одном эксперименте Большого адронного коллайдера в ЦЕРН генерирует около 1 миллиона петабайт 1 необработанных данных (но не все результаты сохраняются).

Физики одни из первых столкнулись с большими данными и уже давно работают с ними — это различные инструменты для хранения, фильтрации и обработки данных: например, Worldwide LHC Computing Grid. В 1990-х годах в Фермилаб обрабатывались уже сотни терабайт данных.

![001](/IntroCourseOnBigData/Pictures/001_002.PNG)

Источник: [Particle physics tames big data](https://www.symmetrymagazine.org/article/august-2012/particle-physics-tames-big-data?language_content_entity=und)

Фильтрация больших наборов данных и управление ими, конечно, не ограничиваются физикой элементарных частиц. Исследователи во всех областях науки, правительства и промышленности также внесли гигантский вклад в это направление.

Мы, в свою очередь, будем определять большие данные достаточно широко и включим в них следующие элементы:
1. ETL / ELT;
2. Технологии хранения больших объёмов структурированных и неструктурированных данных;
3. Технологии обработки таких данных;
4. Управление качеством данных;
5. Технологии предоставления данных потребителю.

[Содержание](#содержание)
<hr>

# Развитие больших данных

Большие данные начали набирать популярность с 2010-х годов, а с 2014 стали трендом. 

Сложно сказать, что послужило триггером. Скорее всего, совпало несколько факторов: 
+ объём генерируемых данных стал достаточно большим,
+ компании научились извлекать из этих данных прибыль,
+ случился технологический прогресс — вычислительные мощности стали доступнее.

По запросам в Google Trends можно отследить зарождение и распространение термина «Big Data»:

![001](/IntroCourseOnBigData/Pictures/001_003.PNG)

На примере соцсетей мы можем наблюдать, что примерно в это время становится всё больше компаний с большим числом пользователей, которые генерируют данные.

![001](/IntroCourseOnBigData/Pictures/001_004.PNG)

С 2014 года на Big Data обратили внимание ведущие мировые вузы, где обучают прикладным инженерным и ИТ-специальностям. Затем к сбору и анализу подключились ИТ-корпорации — Microsoft, IBM, Oracle, EMC, а после Google, Apple, Facebook и Amazon. 

Сегодня большие данные используют крупные компании во всех отраслях, а также госорганы. В общем, практически все, у кого такие данные есть.

Множество компаний делают продукты для Big Data. Оцените их количество:

![001](/IntroCourseOnBigData/Pictures/001_005.PNG)

Источник: [Great Power, Great Responsibility: The 2018 Big Data & AI Landscape](https://mattturck.com/bigdata2018/).
В статье картинка доступна в исходном разрешении. Она немного устарела,
но всё равно прекрасно отображает общую картину

Посмотрим на похожую карту за 2012 год. Рост количества инструментов видно невооружённым взглядом:

![001](/IntroCourseOnBigData/Pictures/001_006.PNG)

Источник: [The Big Data Landscape](https://www.forbes.com/sites/davefeinleib/2012/06/19/the-big-data-landscape/?sh=7716299935e6)

Среди всех решений стоит выделить open source проекты Hadoop и Spark, которые используют чаще остальных. На их основе создано множество других проектов.

[Содержание](#содержание)
<hr>

# Тренды и ограничения в Big Data
Основные тренды в больших данных на текущий момент и перспективы развития:
1. Облачные решения (Everyone, to the Cloud). <br>
Всё больше продуктов и инструментов уходят в облако, и Big Data становится сервисом (Google Cloud, AWS, Microsoft Azure).
2. Машинное обучение и искусственный интеллект.<br> 
Компании чаще начинают использовать большой объём данных не только для аналитики и агрегации, но и для различных моделей машинного обучения.
3. Differential Privacy, IoT, Real Time и прочее.

Есть и ограничения или сдерживающие факторы (кроме наличия самих данных):
1. Нехватка специалистов с нужным уровнем компетенций.
2. Разрозненность ИТ-инфраструктуры и отсутствие механизмов интеграции.

Для Big Data прошёл пик хайпа. Согласно циклу зрелости (Hype Cycle), мы находимся на «плато продуктивности» или приближаемся к нему. Сейчас Big Data — это не что-то новое, а повсеместный эффективный стандартный инструмент.

![001](/IntroCourseOnBigData/Pictures/001_007.PNG)

Источник: [Что такое цикл хайпа?](https://tecedu.academy/ru/blog/cto-takoe-cikl-xaipa)

[Содержание](#содержание)
<hr>

# Распределённые системы
Мы разобрались с тем, что такое большие данные. Теперь обсудим, как эти данные хранить и как с ними работать.

Обработка наборов данных — фундаментальная вычислительная задача, которой, как и ряду других практических задач, изначально свойствен параллелизм, потенциально способный повысить производительность и пропускную способность в многоядерных системах. 

Три основных направления решения этой задачи:
+ параллельные вычисления,
+ распределённые вычисления,
+ грид-вычисления.

__Параллельные вычисления__ — выполняют задачи, используя множество процессоров, разделяющих одну и ту же память. Параллельные вычислительные системы ограничены количеством процессоров, способных работать с разделяемой памятью.

__Распределённые вычисления__ — это группа компьютеров, связанных сетью и не имеющих общую память. Эти компьютеры общаются друг с другом путём передачи сообщений.

__Грид-вычисления__ — это группа компьютеров, связанных сетью и не имеющих общую память. Эти компьютеры общаются друг с другом путём передачи сообщений. В отличие от распределённых вычислений, более разнородны и географически рассредоточены.

![001](/IntroCourseOnBigData/Pictures/001_008.PNG)

Источник: [Быстрый старт в распределённые вычисления: 7 фундаментальных концепций](https://proglib.io/p/bystryy-start-v-raspredelennye-vychisleniya-7-fundamentalnyh-koncepciy-2022-08-24)

Для работы с большим объёмом данных нам нужно масштабировать наши ресурсы, чтобы обрабатывать этот объём данных и делать это быстро.

Производительность на ядро уже давно практически не растёт, что для CPU-bound операций критично. Эту тенденцию можно наблюдать на графике ниже. Поэтому самый доступный способ масштабирования — это многоядерные и многопроцессорные системы.

![001](/IntroCourseOnBigData/Pictures/001_009.PNG)

Источник: [Прошлое роста производительности](https://habr.com/ru/companies/intel/articles/174719/)

_В 2010 вице-президент NVIDIA Билл Дэлли (Bill Dally) в издании Forbes высказался предельно прямолинейно: «Закон Мура 2 мёртв»._ <br>
_Дэлли говорил о том, что двух-, четырех- и шестиядерные процессорные решения неэффективны. Он сравнил такой подход с «попыткой приделать к поезду крылья». По его словам, выход из положения лежит в ориентации на параллельные вычисления._<br>
_Специальные многопоточные решения, разработанные с учётом максимальной мощности и энергоэффективности, смогут вновь обеспечить удвоение производительности каждые два года._

В итоге распределённые системы — способ решения трудоёмких вычислительных задач с использованием двух и более компьютеров, объединённых в сеть.

Закон Мура (англ. Moore's law) — эмпирическое наблюдение, сделанное Гордоном Муром, согласно которому (в современной формулировке) количество транзисторов, размещаемых на кристалле интегральной схемы, удваивается каждые 24 месяца. Часто цитируемый интервал в 18 месяцев связан с прогнозом Давида Хауса из Intel, по мнению которого, производительность процессоров должна удваиваться каждые 18 месяцев из-за сочетания роста количества транзисторов и увеличения тактовых частот процессоров.

__Распределённые вычислительные системы__ — это физические компьютеры и программные системы, реализующие каким-нибудь способом параллельную обработку данных на многих вычислительных компьютерных узлах.<br>
Распределённые вычисления можно назвать частным случаем параллельных вычислений, то есть одновременного решения различных частей одной вычислительной задачи несколькими процессорами одного или нескольких компьютеров. Но термин «параллельные вычисления», как правило, применяется к многоядерным компьютерам или суперкомпьютерам, чтобы подчеркнуть использование многопроцессорной архитектуры с разделяемой памятью.

На базовом уровне масштабируемость можно разделить на два типа:
1. __Вертикальное масштабирование__ — увеличение производительности приложения при добавлении ресурсов в рамках имеющегося оборудования. <br>
Например, увеличение оперативной памяти или замена процессора на более мощный. В этом случае масштабируемость ограниченная (легко достигнуть потолка), и очень дорогая (погуглите стоимость суперкомпьютеров). Способ подходит для параллельных вычислений.

![001](/IntroCourseOnBigData/Pictures/001_010.PNG)

Источник: [Growing compute by scaling up and scaling out](https://developer.ibm.com/articles/scale-up-and-scale-out-vms-vs-containers/)

2. __Горизонтальное масштабирование__ — увеличение производительности приложения за счёт распределения нагрузки между имеющимся и новым оборудованием. До тех пор, пока есть возможность увеличивать количество серверов, есть возможность увеличивать производительность. Способ подходит для распределённых вычислений.

![001](/IntroCourseOnBigData/Pictures/001_011.PNG)

Источник: [Growing compute by scaling up and scaling out](https://developer.ibm.com/articles/scale-up-and-scale-out-vms-vs-containers/)


_Кроме закона Мура, есть также закон Амдала: производительность любой параллельной программы ограничена частью кода, не поддающейся распараллеливанию._

Чтобы приложение могло поддержать горизонтальное масштабирование, код приложения должен поддерживать механизм взаимодействия и синхронизации серверов между собой.

[Содержание](#содержание)
<hr>

# Распределённое программирование

__Распределённое программирование__ — способ обработки данных, при котором различные части программы выполняются на нескольких компьютерах, образующих параллельную вычислительную систему с возможностью наращивания производительности. 

Соответственно, чтобы выполнять задачи для распределённых систем, нужен соответствующий инструментарий.

Мы не будем детально изучать эту тему, так как она довольно сложная и обширная. Отметим лишь, что нам понадобится знание парадигмы функционального программирования, потому что функциональное программирование упрощает разработку параллельных и распределённых систем благодаря отсутствию состояния и возможности использования неизменяемых данных. А также облегчает разработку систем с высокой отказоустойчивостью и масштабируемостью благодаря своей неподверженности побочным эффектам.

![001](/IntroCourseOnBigData/Pictures/001_012.PNG)

Источник: [Параллельное программирование на языке программирования C++](https://znanio.ru/media/parallelnoe-programmirovanie-na-yazyke-programmirovaniya-c--2832487)

__Функциональное программирование__ — это одна из парадигм программирования.

Вычисления в ней понимаются не как последовательность изменения состояний, но как вычисление значений функций в их математическом понимании. То есть функции в ФП — это не подпрограммы, а отображения элементов одного множества на другое по определённым правилам.

Python — современный язык, который полностью поддерживает парадигму функционального программирования. Python содержит функции высшего порядка, например:
1. __map()__ — принимает функцию-аргумент и применяет её ко всем элементам входящей последовательности,
2. __filter()__ — фильтрует последовательность по заданному условию.
3. __reduce()__ — принимает функцию и последовательность; запускает цепь вычислений, применяя функцию ко всем элементам последовательности; сводит набор к единственному значению.

Например, MapReduce состоит из двух шагов: Map и Reduce, названных так по аналогии с одноимёнными функциями высшего порядка — map и reduce.

MapReduce — модель распределённых вычислений, представленная компанией Google.

Используется для параллельных вычислений над большими наборами данных в компьютерных кластерах.

Но не любую задачу можно распараллелить. Задача должна легко разбиваться на более мелкие задачи, каждую из которых можно рассчитывать независимо от других. Это значит, что между такими задачами нет зависимостей, и их можно рассчитывать параллельно или в любом порядке. Иногда такие задачи называют «идеально параллельными» или «отлично параллелизуемыми».

Некоторые подзадачи зависят от результатов предыдущих шагов или подзадач, но это не значит, что они вообще не могут быть параллелизованы.

Распространённый пример очевидно параллельной задачи — это цикл for: каждую итерацию цикла можно выполнять независимо от других. Более сложный пример — метод Монте-Карло: это моделирование, использующее повторение выборок случайной величины для оценки ее распределения. 

Каждая выборка генерируется независимо от других и никак на них не влияет.

Если упростить и оставить для нас только нужное, распределённое программирование — это обработка с помощью функций, например, map, reduce и других логически разделённых файлов, каждую часть которых можно обрабатывать независимо от других разбиений. Кроме этого, нам нужны различные фреймворки, которые будут брать на себя задачи по планированию, коммуникации, синхронизации, обработке ошибок и многому другому. Например, Hadoop MapReduce, Apache Spark и так далее.

[Содержание](#содержание)
<hr>

# Распределённые файловые системы
Для хранения данных используются распределённые файловые системы (БД тоже используют распределённые ФС).

Распределённые файловые системы (distributed file system) работают сразу на многих компьютерах (серверах) с репликацией для защиты от сбоев. Эти файловые системы упрощают доступ к файлам. Пользователи используют единый сетевой ресурс для доступа к файлам, даже если эти файлы физически находятся на разных серверах.

![001](/IntroCourseOnBigData/Pictures/001_013.PNG)

Источник: [HDFS (Hadoop Distributed File System) – StackLima](https://stacklima.com/hadoop-hdfs-systeme-de-fichiers-distribue-hadoop/)

Можно сказать, что распределённые файловые системы — это то, как сегодня хранится большинство данных, особенно «неструктурированных», которые используются при анализе больших данных. Ведь собрать необходимый объём данных на одном компьютере часто невозможно.

Есть много файловых систем, но в рамках данного курса мы будем обсуждать только HDFS — самую распространённую для наших задач.

[Содержание](#содержание)
<hr>

# Системы управления и хранения данных

SQL — универсальный язык данных. Поэтому начнём с СУБД.

Обычно данные хранятся в виде таблиц: они структурированы и разложены по строкам и столбцам, чтобы ими легче было оперировать. Сами по себе таблицы или база данных не могут выполнять операции. Для этого есть СУБД, которые позволяют создавать новые таблицы, удалять ненужные данные, настраивать ключи и обрабатывать запросы.

С основными задачами СУБД и разновидностями моделей данных вы уже знакомы.

Вспомним лишь то, что основной язык для работы с данными — SQL, а данные чаще всего хранятся в реляционных либо объектно-реляционных базах данных. Большие данные не очень хорошо подходят для реляционной модели. Поэтому появились NoSQL БД, которые позволяют оперативно обрабатывать огромные объёмы данных. NoSQL по большей части заточена под масштабирование по горизонтали и работу с недостаточно  структурированными или постоянно меняющимися данными.

![001](/IntroCourseOnBigData/Pictures/001_014.PNG)

Источник: [SQL vs NoSQL: Choosing Database Design](https://lo-victoria.com/sql-vs-nosql-choosing-database-design)

Это связано с тем, что данные стали храниться распределённо, для чего требуется распределённая БД. Вертикальное масштабирование железа — удовольствие дорогое, а шардированию реляционные БД поддаются плохо: чем больше в системе серверов, тем больше усилий требуется для поддержания согласованности данных в узлах.

Работа с данными ускорилась. В отличие от нереляционных БД, SQL запрашивает данные из нескольких таблиц. А когда количество информации растёт, таблиц и связей становится слишком много, поэтому скорость получения ответа на запрос снижается.

Разработчики стремились избавиться от ограниченности реляционных схем.

Жёсткая реляционная модель подходит не для всех предметных областей. Иногда они слишком сложны или часто требуют корректировки данных. В итоге получается либо нагромождение избыточного количества таблиц, либо плохо структурированная предметная область.

Кратко об отличиях:

|   | Реляционные базы данных | Базы данных NoSQL |
|---|---|---|
| __Модель данных__ | Реляционная модель нормализует данные и преобразует их в  таблицы из строк и столбцов. Схема жёстко задаёт таблицы, строки, столбцы, индексы, отношения между таблицами и прочие элементы базы данных | Базы данных NoSQL предоставляют разнообразные модели данных, такие как пары «ключ-значение», документы и графы, оптимизированные для высокой производительности и масштабируемости |
| __Свойства ACID__ | Реляционные базы данных обеспечивают набор свойств ACID | Базы данных NoSQL зачастую предлагают компромисс: смягчают жёсткие требования свойств ACID ради более гибкой модели данных, которая допускает горизонтальное масштабирование |
| __Производительность__ | Производительность главным образом зависит от дисковой подсистемы. Чтобы обеспечить максимальную производительность, часто требуется  оптимизация запросов, индексов и структуры таблицы | Производительность обычно зависит от размера кластера базового аппаратного обеспечения, задержки сети и вызывающего приложения |
| __Масштабирование__ | Реляционные базы данных обычно масштабируются путём увеличения вычислительных возможностей аппаратного обеспечения или добавления отдельных копий для рабочих нагрузок чтения | Базы данных NoSQL обычно поддерживают высокую разделяемость благодаря шаблонам доступа с возможностью масштабирования на основе распределённой архитектуры. Это повышает пропускную способность и обеспечивает устойчивую производительность почти в неограниченных масштабах |
| __API__ | Запросы на запись и извлечение данных составляются на языке SQL | Объектно‑ориентированные API позволяют разработчикам приложений без труда записывать и извлекать структуры данных. Обычно есть поддержка SQL |

Выделим плюсы NoSQL (плюсы реляционных БД вы уже проходили):

+ __Гибкость.__ Как правило, базы данных NoSQL предлагают гибкие схемы. Благодаря использованию гибких моделей данных, БД NoSQL хорошо подходят для частично структурированных и неструктурированных данных.
+ __Масштабируемость.__ Базы данных NoSQL рассчитаны на масштабирование с использованием распределённых кластеров аппаратного обеспечения, а не путём добавления дорогих надёжных серверов.
+ __Высокая производительность.__ Базы данных NoSQL оптимизированы для конкретных моделей данных и шаблонов доступа, что позволяет достичь более высокой производительности по сравнению с реляционными базами данных.

![001](/IntroCourseOnBigData/Pictures/001_015.PNG)

Источник: [SQL vs NoSQL: Choosing Database Design](https://lo-victoria.com/sql-vs-nosql-choosing-database-design)

Подробнее про модели данных:
1. __Базы данных по принципу «ключ-значение» (key-value store).__ <br>
В таких БД записи хранятся в парах «ключ-значение», где ключ выступает уникальным идентификатором. Ключи и значения фиксируются в виде простой или составной информации.<br>
Эти хранилища максимально быстро реагируют на запросы информации и прекрасно масштабируются. Key-value СУБД часто используют для систем, в которых скорость — это приоритет, а данные не слишком сложные. Например, для хранения кэша данных, онлайн-списков, обработки истечения срока действия, разделения сеансов, построения рейтинга и прочих задач. <br>
Яркий пример key-value store БД — Redis. Ей пользуются Airbnb, Slack, Twitter и Uber. Система целиком работает в оперативной памяти, что позволяет информации считываться и записываться намного быстрее, чем даже на очень шустрые твердотельные накопители.

2. __Колоночные базы данных (column family store).__<br>
У этих БД есть свои столбцы и строки, но информация записывается в колонки. Колонки между собой не связаны, поэтому удаление или добавление новых свойств не затрагивает остальную систему. Отсутствие заранее заданной схемы позволяет хранить в этих NoSQL-базах записи без чёткой структуры.<br>
В традиционной СУБД при выполнении запроса сканируется вся таблица, а информация из всей строки извлекается целиком. В колоночных БД выгружаются только необходимые значения, поскольку поиск ведётся по отдельным столбцам. Такой подход колоночных NoSQL баз к хранению информации позволяет быстро получать данные из больших таблиц для анализа. А возможность сильного сжатия данных экономит много места на диске.<br>
В этой категории существуют базы ClickHouse, Vertica, Cassandra и другие. Netflix, например, в том числе использует хранилище Cassandra: база легко масштабируется и у неё нет единых точек отказа.

3. __Документоориентированные базы данных (Document-oriented store).__ <br>
В БД этого типа данные записываются в документы и хранятся в формате, подобном JSON. Таким хранилищам свойственны иерархичность (документы складываются в коллекции, а коллекции группируются логически) и гибкость (значения, свойства и их структура может меняться в процессе разработки).<br>
Document-oriented-модель хороша в проектах, где нужно обрабатывать большой объём данных без чёткой структуры, а также для работы со множеством уникальных документов, которые со временем требуют изменений. Например, для каталогов товаров, соцсетей, платформ с блогами и видео, геоаналитики и в других сферах.<br>
Классический пример такой нереляционной СУБД — MongoDB.

4. __Графовые базы данных (graph store).__ <br>
Этот тип БД, основанный на топографической структуре сети, используется для выполнения задач, ориентированных на связи: для алгоритмов рекомендаций контента, социальных сетей, обнаружения случаев сетевого мошенничества. <br>
К графовым относятся базы данных Neo4j, OrientDB.

Для различных потребностей используются разные хранилища данных. И NoSQL не заменяет другие СУБД.

![001](/IntroCourseOnBigData/Pictures/001_016.PNG)

Источник: [BigData: Issues, Challenges, Technologies and Methods](https://www.researchgate.net/publication/315670334_BigData_Issues_Challenges_Technologies_and_Methods)

Стоит отметить, что NoSQL — неудачное имя для СУБД, так как большинство из них поддерживает SQL, а также существует реляционная (малоизвестная) СУБД, которая называется так же.

[Содержание](#содержание)
<hr>

# Форматы хранения данных

Все форматы файлов (включая и форматы для хранения текстовых документов в файлах) можно подразделить на бинарные и текстовые. 

Текстовый формат файла — это формат, основанный на plain text. Вся информация представлена в виде текста. В текстовом формате можно представить любую информацию, но её нужно закодировать в текстовый вид. Особенно популярны текстовые форматы, разумеется, для текстовых документов. 

Пример: txt. 

Но текстовый формат используется также для csv, xml, html и так далее.

Формат файла, не основанный на plain text, называется бинарным (от binary — «двоичный», поскольку в нём может использоваться любая последовательность двоичных данных). 

Например, офисный пакет Microsoft Office хранит документы, как правило, в файлах бинарных форматов.

У бинарных файлов есть преимущества перед текстовыми — в них можно реализовать следующий функционал:
1. Более быстрое время чтения.
2. Более быстрое время записи.
3. Разделяемые файлы.
4. Поддержка эволюции схем.
5. Расширенная поддержка сжатия.

Чтобы ускорить обработку данных, создавались форматы: Avro, Parquet, ORC и другие.

Время поиска, чтения и записи — часто узкое горлышко при работе с данными. Эти проблемы усугубляются трудностями в управлении большими наборами данных. Обработка больших данных увеличивает нагрузку на подсистему хранения — HDFS хранит данные избыточно для достижения отказоустойчивости. Кроме дисков, нагружаются процессор, сеть, система ввода-вывода и так далее. 

По мере роста объёма данных увеличивается и стоимость их обработки и хранения.

Отличия форматов:
1. Avro — формат хранения по строкам, Parquet — хранение по столбцам.
2. Parquet лучше подходит для аналитических запросов, то есть операции чтения и запрос данных гораздо эффективнее, чем запись. Операции записи эффективнее в Avro.
3. Avro более зрело работает с эволюцией схем. Parquet поддерживает только добавление схемы, а в Avro реализована многофункциональная эволюция, то есть добавление или изменение столбцов.
4. Parquet идеально подходит для запроса подмножества столбцов в многоколоночной таблице. Avro — для операций ETL, где мы запрашиваем все столбцы.
5. Parquet лучше хранит вложенные данные, чем ORC.
6. ORC лучше приспособлен к проталкиванию предикатов (predicate pushdown).
7. ORC поддерживает свойства ACID.
8. ORC лучше сжимает данные.

[Содержание](#содержание)
<hr>

# Выводы

На этой лекции мы познакомились с несколькими определениями обширного термина «Big Data», с его назначением и краткой историей. Узнали, что масштабирование данных бывает вертикальным и горизонтальным. Рассмотрели новый тип СУБД NoSQL, выявили его преимущества и недостатки в сравнении с реляционными базами данных. Эта лекция станет нашим мостиком к более глубокому изучению Big Data.

[Содержание](#содержание)
<hr>

# Что можно почитать ещё?

Introducing Data Science / Davy Cielen, Arno D. B. Meysman, Mohamed Ali

## Вопросы к лекции

+ У вас 5 ТБ данных, необходимость аналитики — 1 год. Является ли ваша работа с этими данными Big Data?
+ Какое масштабирование вы посоветуете дата-центру при условии, что вся свободная площадь для серверов уже занята?
+ Вопрос для самостоятельного изучения: всегда ли БД ключ-значение — это хэш-таблица?
+ Что такое NameNode и при чём тут сердцебиение?

[Содержание](#содержание)
<hr>

# Используемая литература
1. [Журнал Nature, выпуск от 4 сентября 2008](https://www.nature.com/nature/volumes/455/issues/7209)
2. [Большие данные — Википедия](https://ru.wikipedia.org/wiki/%D0%91%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D0%B5_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5)
3. [Big Data Technology that is used at CERN for Data Analysis - Aalpha](https://www.aalpha.net/articles/big-data-technology-that-is-used-at-cern-for-data-analysis/)
4. [Biggest social media platforms 2023 | Statista](https://www.statista.com/statistics/272014/global-social-networks-ranked-by-number-of-users/)
5. [[Best of 2019] The most popular social media networks each year, gloriously animated](https://thenextweb.com/tech/2019/06/11/most-popular-social-media-networks-year-animated/)
6. [Great Power, Great Responsibility: The 2018 Big Data & AI Landscape – Matt Turck](https://mattturck.com/bigdata2018/)
7. [Gartner Hype Cycle Research Methodology](https://mattturck.com/bigdata2018/)
8. [Understanding Gartner’s Hype Cycles](https://www.gartner.com/en/documents/3887767)
9. [Прошлое роста производительности: конец гонки частот, многоядерность и почему прогресс увяз на одном месте](https://habr.com/en/company/intel/blog/174719/)
10. [Быстрый старт в распределенные вычисления: 7 фундаментальных концепций](https://proglib.io/p/bystryy-start-v-raspredelennye-vychisleniya-7-fundamentalnyh-koncepciy-2022-08-24)

[Содержание](#содержание)
<hr>

