# Вводный курс по Big Data (лекции)

## Содержание

[1. Введение в большие данные](#введение-в-большие-данные)
+ [Введение](#введение)
+ [Термины, используемые в лекции](#термины-используемые-в-лекции)
+ [Что такое Big Data](#что-такое-big-data)
+ [Развитие больших данных](#развитие-больших-данных)
+ [Тренды и ограничения в Big Data](#тренды-и-ограничения-в-big-data)
+ [Распределённые системы](#распределённые-системы)
+ [Распределённое программирование](#распределённое-программирование)
+ [Распределённые файловые системы](#распределённые-файловые-системы)
+ [Системы управления и хранения данных](#системы-управления-и-хранения-данных)
+ [Форматы хранения данных](#форматы-хранения-данных)
+ [Выводы](#выводы)
+ [Что можно почитать ещё?](#что-можно-почитать-ещё)
+ [Вопросы к лекции](#вопросы-к-лекции)
+ [Используемая литература](#используемая-литература)

[2. SQL и BigData](#sql-и-bigdata)

+ [Введение](#введение-2)
+ [Термины, используемые в лекции](#термины-используемые-в-лекции-2)
+ [Экосистема Hadoop](#экосистема-hadoop)
    + [Основные компоненты](#основные-компоненты)
        + [MapReduce](#mapreduce)
        + [YARN](#yarn)
        + [HDFS](#hdfs)
    + [Другие инструменты Hadoop](#другие-инструменты-hadoop)
+ [SQL на больших данных](#sql-на-больших-данных)
    + [Apache Hive](#apache-hive)
    + [Apache Impala](#apache-impala)
    + [Apache Drill](#apache-drill)
    + [Presto / Trino](#presto--trino)
    + [Apache Hue](#apache-hue)
    + [Облака](#облака)
+ [Итог]()
+ [Домашнее задание]()
+ [Что можно почитать ещё?]()
+ `[Используемая литература]()

# Введение в большие данные

## Введение
Этот курс создан для погружения в мир больших данных. В результате следующих трёх уроков мы:
+ расширим свои знания в области Big Data;
+ узнаем, как происходит работа с большими данными и в чём отличие от стандартных подходов;
+ рассмотрим основные инструменты для работы Big Data-специалиста.

К концу курса мы поймём, где и зачем нужна Big Data, какие технологии и навыки нужны для старта карьеры в этой сфере.<br>
На первой лекции познакомимся с понятием «Big Data» и узнаем, где оно применяется. А также рассмотрим базовые концепции и инструменты, которые используются вместе с большими данными.

[Содержание](#содержание)
<hr>

## Термины, используемые в лекции

__База данных (БД)__ — совокупность взаимосвязанных и хранящихся вместе данных, организованных и хранимых специальным образом.

__Система управления базой данных (СУБД)__ — совокупность языковых и программных средств для создания, ведения и совместного использования БД.

__ACID__ — набор свойств транзакций базы данных, призванных гарантировать достоверность данных, несмотря на ошибки и сбои. Аббревиатура от atomicity, consistency, isolation, durability — атомарность, согласованность, изолированность, надёжность.

__Машинное обучение__ — наука о разработке алгоритмов и статистических моделей, которые решают определённые задачи, полагаясь на шаблоны и логические выводы.

__API__ — набор команд, которыми одна компьютерная программа может взаимодействовать с другой.

__CPU-Bound операции__ — операции, которые нагружают вычислительные мощности устройства. CPU-Bound операциям противопоставляются I/O-Bound операции, время выполнения которых в основном регулируется временем выполнения всех операций ввода/вывода.

__Шардирование__ — принцип проектирования базы данных, при котором логически независимые строки таблицы БД хранятся раздельно, заранее сгруппированные в секции, которые размещаются на разных физически и логически независимых серверах.

__ETL__ — процесс извлечения, преобразования и загрузки данных.

__ELT__ — процесс извлечения, загрузки и преобразования данных.

[Содержание](#содержание)
<hr>

## Что такое Big Data

Термин «Big Data» (большие данные) предложил редактор журнала Nature Клиффорд Линч в [спецвыпуске](https://www.nature.com/nature/volumes/455/issues/7209) 2008 года, где говорил о взрывном росте объёмов информации в мире. К большим данным Линч отнёс любые массивы неоднородных данных более 150 Гб в сутки. Однако единого критерия больших данных до сих пор нет.

Обычно выделяют три свойства, характерные для больших данных. Их называют «три V» или VVV:
1. __Volume__ — большой объём. <br>
Ценность таких данных не всегда известна. Это могут быть данные каналов Twitter, данные посещаемости веб-страниц, данные мобильных приложений, сетевой трафик, данные датчиков и прочее.<br>
В некоторых организациях хранятся десятки терабайт данных, в других — сотни петабайт.

2. __Velocity__ — скорость появления и обработки данных. В том числе обработка в реальном времени.
3. __Variety__ — разнообразие типов данных. Неструктурированные и полуструктурированные типы данных, такие как текст, аудио и видео, требуют дополнительной обработки для определения их значения и метаданных.

_Набор признаков volume, velocity, variety выработан в 2001 году вне контекста больших данных, а в связи с ростом популярности концепции центрального хранилища данных для организаций. Отмечалась равнозначность проблематик управления данными по всем трём аспектам._

Часто к трём V добавляют ещё три V:

4. __Veracity__ — достоверность как самого набора данных, так и результатов его анализа;
5. __Variability__ — изменчивость. У потоков данных бывают свои пики и спады под влиянием сезонов или социальных явлений.
6. __Value__ — ценность или значимость. Как и любая информация, большие данные могут быть простыми или сложными для восприятия и анализа. Пример
простых данных — посты в соцсетях, сложных — банковские транзакции.

_Есть множество интерпретаций: с четырьмя V, пятью V, семью V (добавляется визуализация — visualization) и даже с десятью V._ <br>
_Иногда участники рынка интерпретируют некоторые V неодинаково._

Получается, мы имеем что-то объёмное, изменчивое и неструктурированное, и это что-то нужно уметь достаточно быстро обрабатывать, чтобы результатами обработки успели воспользоваться заинтересованные лица. При этом, чем нестабильнее, изменчивее, разнообразнее поток данных, тем сложнее его анализировать.

Понятие «Big Data» конкретно не определено. Одни и те же данные для разных компаний могут быть как большими, так и нет, в зависимости от того, как часто и быстро их нужно обрабатывать.

Можно встретить такое определение: __большие данные__ — это набор данных, размер которых превосходит возможности типичных баз данных (БД) по занесению, хранению, управлению и анализу информации.

Определяющей характеристикой для больших данных часто выступает не только их объём, но и другие категории, существенные для представления о сложности их обработки и анализа.

Типичные примеры больших данных:
+ транзакции,
+ соцсети (сообщения, клики, фото),
+ информация о клиентах (звонки, телеметрия),
+ датчики (интернет вещей),
+ сетевой трафик,
+ научные исследования (Большой адронный коллайдер, телескопы) и так далее.

![001](/IntroCourseOnBigData/Pictures/001_001.PNG)

Год столкновений в одном эксперименте Большого адронного коллайдера в ЦЕРН генерирует около 1 миллиона петабайт 1 необработанных данных (но не все результаты сохраняются).

Физики одни из первых столкнулись с большими данными и уже давно работают с ними — это различные инструменты для хранения, фильтрации и обработки данных: например, Worldwide LHC Computing Grid. В 1990-х годах в Фермилаб обрабатывались уже сотни терабайт данных.

![001](/IntroCourseOnBigData/Pictures/001_002.PNG)

Источник: [Particle physics tames big data](https://www.symmetrymagazine.org/article/august-2012/particle-physics-tames-big-data?language_content_entity=und)

Фильтрация больших наборов данных и управление ими, конечно, не ограничиваются физикой элементарных частиц. Исследователи во всех областях науки, правительства и промышленности также внесли гигантский вклад в это направление.

Мы, в свою очередь, будем определять большие данные достаточно широко и включим в них следующие элементы:
1. ETL / ELT;
2. Технологии хранения больших объёмов структурированных и неструктурированных данных;
3. Технологии обработки таких данных;
4. Управление качеством данных;
5. Технологии предоставления данных потребителю.

[Содержание](#содержание)
<hr>

## Развитие больших данных

Большие данные начали набирать популярность с 2010-х годов, а с 2014 стали трендом. 

Сложно сказать, что послужило триггером. Скорее всего, совпало несколько факторов: 
+ объём генерируемых данных стал достаточно большим,
+ компании научились извлекать из этих данных прибыль,
+ случился технологический прогресс — вычислительные мощности стали доступнее.

По запросам в Google Trends можно отследить зарождение и распространение термина «Big Data»:

![001](/IntroCourseOnBigData/Pictures/001_003.PNG)

На примере соцсетей мы можем наблюдать, что примерно в это время становится всё больше компаний с большим числом пользователей, которые генерируют данные.

![001](/IntroCourseOnBigData/Pictures/001_004.PNG)

С 2014 года на Big Data обратили внимание ведущие мировые вузы, где обучают прикладным инженерным и ИТ-специальностям. Затем к сбору и анализу подключились ИТ-корпорации — Microsoft, IBM, Oracle, EMC, а после Google, Apple, Facebook и Amazon. 

Сегодня большие данные используют крупные компании во всех отраслях, а также госорганы. В общем, практически все, у кого такие данные есть.

Множество компаний делают продукты для Big Data. Оцените их количество:

![001](/IntroCourseOnBigData/Pictures/001_005.PNG)

Источник: [Great Power, Great Responsibility: The 2018 Big Data & AI Landscape](https://mattturck.com/bigdata2018/).
В статье картинка доступна в исходном разрешении. Она немного устарела,
но всё равно прекрасно отображает общую картину

Посмотрим на похожую карту за 2012 год. Рост количества инструментов видно невооружённым взглядом:

![001](/IntroCourseOnBigData/Pictures/001_006.PNG)

Источник: [The Big Data Landscape](https://www.forbes.com/sites/davefeinleib/2012/06/19/the-big-data-landscape/?sh=7716299935e6)

Среди всех решений стоит выделить open source проекты Hadoop и Spark, которые используют чаще остальных. На их основе создано множество других проектов.

[Содержание](#содержание)
<hr>

## Тренды и ограничения в Big Data
Основные тренды в больших данных на текущий момент и перспективы развития:
1. Облачные решения (Everyone, to the Cloud). <br>
Всё больше продуктов и инструментов уходят в облако, и Big Data становится сервисом (Google Cloud, AWS, Microsoft Azure).
2. Машинное обучение и искусственный интеллект.<br> 
Компании чаще начинают использовать большой объём данных не только для аналитики и агрегации, но и для различных моделей машинного обучения.
3. Differential Privacy, IoT, Real Time и прочее.

Есть и ограничения или сдерживающие факторы (кроме наличия самих данных):
1. Нехватка специалистов с нужным уровнем компетенций.
2. Разрозненность ИТ-инфраструктуры и отсутствие механизмов интеграции.

Для Big Data прошёл пик хайпа. Согласно циклу зрелости (Hype Cycle), мы находимся на «плато продуктивности» или приближаемся к нему. Сейчас Big Data — это не что-то новое, а повсеместный эффективный стандартный инструмент.

![001](/IntroCourseOnBigData/Pictures/001_007.PNG)

Источник: [Что такое цикл хайпа?](https://tecedu.academy/ru/blog/cto-takoe-cikl-xaipa)

[Содержание](#содержание)
<hr>

## Распределённые системы
Мы разобрались с тем, что такое большие данные. Теперь обсудим, как эти данные хранить и как с ними работать.

Обработка наборов данных — фундаментальная вычислительная задача, которой, как и ряду других практических задач, изначально свойствен параллелизм, потенциально способный повысить производительность и пропускную способность в многоядерных системах. 

Три основных направления решения этой задачи:
+ параллельные вычисления,
+ распределённые вычисления,
+ грид-вычисления.

__Параллельные вычисления__ — выполняют задачи, используя множество процессоров, разделяющих одну и ту же память. Параллельные вычислительные системы ограничены количеством процессоров, способных работать с разделяемой памятью.

__Распределённые вычисления__ — это группа компьютеров, связанных сетью и не имеющих общую память. Эти компьютеры общаются друг с другом путём передачи сообщений.

__Грид-вычисления__ — это группа компьютеров, связанных сетью и не имеющих общую память. Эти компьютеры общаются друг с другом путём передачи сообщений. В отличие от распределённых вычислений, более разнородны и географически рассредоточены.

![001](/IntroCourseOnBigData/Pictures/001_008.PNG)

Источник: [Быстрый старт в распределённые вычисления: 7 фундаментальных концепций](https://proglib.io/p/bystryy-start-v-raspredelennye-vychisleniya-7-fundamentalnyh-koncepciy-2022-08-24)

Для работы с большим объёмом данных нам нужно масштабировать наши ресурсы, чтобы обрабатывать этот объём данных и делать это быстро.

Производительность на ядро уже давно практически не растёт, что для CPU-bound операций критично. Эту тенденцию можно наблюдать на графике ниже. Поэтому самый доступный способ масштабирования — это многоядерные и многопроцессорные системы.

![001](/IntroCourseOnBigData/Pictures/001_009.PNG)

Источник: [Прошлое роста производительности](https://habr.com/ru/companies/intel/articles/174719/)

_В 2010 вице-президент NVIDIA Билл Дэлли (Bill Dally) в издании Forbes высказался предельно прямолинейно: «Закон Мура 2 мёртв»._ <br>
_Дэлли говорил о том, что двух-, четырех- и шестиядерные процессорные решения неэффективны. Он сравнил такой подход с «попыткой приделать к поезду крылья». По его словам, выход из положения лежит в ориентации на параллельные вычисления._<br>
_Специальные многопоточные решения, разработанные с учётом максимальной мощности и энергоэффективности, смогут вновь обеспечить удвоение производительности каждые два года._

В итоге распределённые системы — способ решения трудоёмких вычислительных задач с использованием двух и более компьютеров, объединённых в сеть.

Закон Мура (англ. Moore's law) — эмпирическое наблюдение, сделанное Гордоном Муром, согласно которому (в современной формулировке) количество транзисторов, размещаемых на кристалле интегральной схемы, удваивается каждые 24 месяца. Часто цитируемый интервал в 18 месяцев связан с прогнозом Давида Хауса из Intel, по мнению которого, производительность процессоров должна удваиваться каждые 18 месяцев из-за сочетания роста количества транзисторов и увеличения тактовых частот процессоров.

__Распределённые вычислительные системы__ — это физические компьютеры и программные системы, реализующие каким-нибудь способом параллельную обработку данных на многих вычислительных компьютерных узлах.<br>
Распределённые вычисления можно назвать частным случаем параллельных вычислений, то есть одновременного решения различных частей одной вычислительной задачи несколькими процессорами одного или нескольких компьютеров. Но термин «параллельные вычисления», как правило, применяется к многоядерным компьютерам или суперкомпьютерам, чтобы подчеркнуть использование многопроцессорной архитектуры с разделяемой памятью.

На базовом уровне масштабируемость можно разделить на два типа:
1. __Вертикальное масштабирование__ — увеличение производительности приложения при добавлении ресурсов в рамках имеющегося оборудования. <br>
Например, увеличение оперативной памяти или замена процессора на более мощный. В этом случае масштабируемость ограниченная (легко достигнуть потолка), и очень дорогая (погуглите стоимость суперкомпьютеров). Способ подходит для параллельных вычислений.

![001](/IntroCourseOnBigData/Pictures/001_010.PNG)

Источник: [Growing compute by scaling up and scaling out](https://developer.ibm.com/articles/scale-up-and-scale-out-vms-vs-containers/)

2. __Горизонтальное масштабирование__ — увеличение производительности приложения за счёт распределения нагрузки между имеющимся и новым оборудованием. До тех пор, пока есть возможность увеличивать количество серверов, есть возможность увеличивать производительность. Способ подходит для распределённых вычислений.

![001](/IntroCourseOnBigData/Pictures/001_011.PNG)

Источник: [Growing compute by scaling up and scaling out](https://developer.ibm.com/articles/scale-up-and-scale-out-vms-vs-containers/)


_Кроме закона Мура, есть также закон Амдала: производительность любой параллельной программы ограничена частью кода, не поддающейся распараллеливанию._

Чтобы приложение могло поддержать горизонтальное масштабирование, код приложения должен поддерживать механизм взаимодействия и синхронизации серверов между собой.

[Содержание](#содержание)
<hr>

## Распределённое программирование

__Распределённое программирование__ — способ обработки данных, при котором различные части программы выполняются на нескольких компьютерах, образующих параллельную вычислительную систему с возможностью наращивания производительности. 

Соответственно, чтобы выполнять задачи для распределённых систем, нужен соответствующий инструментарий.

Мы не будем детально изучать эту тему, так как она довольно сложная и обширная. Отметим лишь, что нам понадобится знание парадигмы функционального программирования, потому что функциональное программирование упрощает разработку параллельных и распределённых систем благодаря отсутствию состояния и возможности использования неизменяемых данных. А также облегчает разработку систем с высокой отказоустойчивостью и масштабируемостью благодаря своей неподверженности побочным эффектам.

![001](/IntroCourseOnBigData/Pictures/001_012.PNG)

Источник: [Параллельное программирование на языке программирования C++](https://znanio.ru/media/parallelnoe-programmirovanie-na-yazyke-programmirovaniya-c--2832487)

__Функциональное программирование__ — это одна из парадигм программирования.

Вычисления в ней понимаются не как последовательность изменения состояний, но как вычисление значений функций в их математическом понимании. То есть функции в ФП — это не подпрограммы, а отображения элементов одного множества на другое по определённым правилам.

Python — современный язык, который полностью поддерживает парадигму функционального программирования. Python содержит функции высшего порядка, например:
1. __map()__ — принимает функцию-аргумент и применяет её ко всем элементам входящей последовательности,
2. __filter()__ — фильтрует последовательность по заданному условию.
3. __reduce()__ — принимает функцию и последовательность; запускает цепь вычислений, применяя функцию ко всем элементам последовательности; сводит набор к единственному значению.

Например, MapReduce состоит из двух шагов: Map и Reduce, названных так по аналогии с одноимёнными функциями высшего порядка — map и reduce.

MapReduce — модель распределённых вычислений, представленная компанией Google.

Используется для параллельных вычислений над большими наборами данных в компьютерных кластерах.

Но не любую задачу можно распараллелить. Задача должна легко разбиваться на более мелкие задачи, каждую из которых можно рассчитывать независимо от других. Это значит, что между такими задачами нет зависимостей, и их можно рассчитывать параллельно или в любом порядке. Иногда такие задачи называют «идеально параллельными» или «отлично параллелизуемыми».

Некоторые подзадачи зависят от результатов предыдущих шагов или подзадач, но это не значит, что они вообще не могут быть параллелизованы.

Распространённый пример очевидно параллельной задачи — это цикл for: каждую итерацию цикла можно выполнять независимо от других. Более сложный пример — метод Монте-Карло: это моделирование, использующее повторение выборок случайной величины для оценки ее распределения. 

Каждая выборка генерируется независимо от других и никак на них не влияет.

Если упростить и оставить для нас только нужное, распределённое программирование — это обработка с помощью функций, например, map, reduce и других логически разделённых файлов, каждую часть которых можно обрабатывать независимо от других разбиений. Кроме этого, нам нужны различные фреймворки, которые будут брать на себя задачи по планированию, коммуникации, синхронизации, обработке ошибок и многому другому. Например, Hadoop MapReduce, Apache Spark и так далее.

[Содержание](#содержание)
<hr>

## Распределённые файловые системы
Для хранения данных используются распределённые файловые системы (БД тоже используют распределённые ФС).

Распределённые файловые системы (distributed file system) работают сразу на многих компьютерах (серверах) с репликацией для защиты от сбоев. Эти файловые системы упрощают доступ к файлам. Пользователи используют единый сетевой ресурс для доступа к файлам, даже если эти файлы физически находятся на разных серверах.

![001](/IntroCourseOnBigData/Pictures/001_013.PNG)

Источник: [HDFS (Hadoop Distributed File System) – StackLima](https://stacklima.com/hadoop-hdfs-systeme-de-fichiers-distribue-hadoop/)

Можно сказать, что распределённые файловые системы — это то, как сегодня хранится большинство данных, особенно «неструктурированных», которые используются при анализе больших данных. Ведь собрать необходимый объём данных на одном компьютере часто невозможно.

Есть много файловых систем, но в рамках данного курса мы будем обсуждать только HDFS — самую распространённую для наших задач.

[Содержание](#содержание)
<hr>

## Системы управления и хранения данных

SQL — универсальный язык данных. Поэтому начнём с СУБД.

Обычно данные хранятся в виде таблиц: они структурированы и разложены по строкам и столбцам, чтобы ими легче было оперировать. Сами по себе таблицы или база данных не могут выполнять операции. Для этого есть СУБД, которые позволяют создавать новые таблицы, удалять ненужные данные, настраивать ключи и обрабатывать запросы.

С основными задачами СУБД и разновидностями моделей данных вы уже знакомы.

Вспомним лишь то, что основной язык для работы с данными — SQL, а данные чаще всего хранятся в реляционных либо объектно-реляционных базах данных. Большие данные не очень хорошо подходят для реляционной модели. Поэтому появились NoSQL БД, которые позволяют оперативно обрабатывать огромные объёмы данных. NoSQL по большей части заточена под масштабирование по горизонтали и работу с недостаточно  структурированными или постоянно меняющимися данными.

![001](/IntroCourseOnBigData/Pictures/001_014.PNG)

Источник: [SQL vs NoSQL: Choosing Database Design](https://lo-victoria.com/sql-vs-nosql-choosing-database-design)

Это связано с тем, что данные стали храниться распределённо, для чего требуется распределённая БД. Вертикальное масштабирование железа — удовольствие дорогое, а шардированию реляционные БД поддаются плохо: чем больше в системе серверов, тем больше усилий требуется для поддержания согласованности данных в узлах.

Работа с данными ускорилась. В отличие от нереляционных БД, SQL запрашивает данные из нескольких таблиц. А когда количество информации растёт, таблиц и связей становится слишком много, поэтому скорость получения ответа на запрос снижается.

Разработчики стремились избавиться от ограниченности реляционных схем.

Жёсткая реляционная модель подходит не для всех предметных областей. Иногда они слишком сложны или часто требуют корректировки данных. В итоге получается либо нагромождение избыточного количества таблиц, либо плохо структурированная предметная область.

Кратко об отличиях:

|   | Реляционные базы данных | Базы данных NoSQL |
|---|---|---|
| __Модель данных__ | Реляционная модель нормализует данные и преобразует их в  таблицы из строк и столбцов. Схема жёстко задаёт таблицы, строки, столбцы, индексы, отношения между таблицами и прочие элементы базы данных | Базы данных NoSQL предоставляют разнообразные модели данных, такие как пары «ключ-значение», документы и графы, оптимизированные для высокой производительности и масштабируемости |
| __Свойства ACID__ | Реляционные базы данных обеспечивают набор свойств ACID | Базы данных NoSQL зачастую предлагают компромисс: смягчают жёсткие требования свойств ACID ради более гибкой модели данных, которая допускает горизонтальное масштабирование |
| __Производительность__ | Производительность главным образом зависит от дисковой подсистемы. Чтобы обеспечить максимальную производительность, часто требуется  оптимизация запросов, индексов и структуры таблицы | Производительность обычно зависит от размера кластера базового аппаратного обеспечения, задержки сети и вызывающего приложения |
| __Масштабирование__ | Реляционные базы данных обычно масштабируются путём увеличения вычислительных возможностей аппаратного обеспечения или добавления отдельных копий для рабочих нагрузок чтения | Базы данных NoSQL обычно поддерживают высокую разделяемость благодаря шаблонам доступа с возможностью масштабирования на основе распределённой архитектуры. Это повышает пропускную способность и обеспечивает устойчивую производительность почти в неограниченных масштабах |
| __API__ | Запросы на запись и извлечение данных составляются на языке SQL | Объектно‑ориентированные API позволяют разработчикам приложений без труда записывать и извлекать структуры данных. Обычно есть поддержка SQL |

Выделим плюсы NoSQL (плюсы реляционных БД вы уже проходили):

+ __Гибкость.__ Как правило, базы данных NoSQL предлагают гибкие схемы. Благодаря использованию гибких моделей данных, БД NoSQL хорошо подходят для частично структурированных и неструктурированных данных.
+ __Масштабируемость.__ Базы данных NoSQL рассчитаны на масштабирование с использованием распределённых кластеров аппаратного обеспечения, а не путём добавления дорогих надёжных серверов.
+ __Высокая производительность.__ Базы данных NoSQL оптимизированы для конкретных моделей данных и шаблонов доступа, что позволяет достичь более высокой производительности по сравнению с реляционными базами данных.

![001](/IntroCourseOnBigData/Pictures/001_015.PNG)

Источник: [SQL vs NoSQL: Choosing Database Design](https://lo-victoria.com/sql-vs-nosql-choosing-database-design)

Подробнее про модели данных:
1. __Базы данных по принципу «ключ-значение» (key-value store).__ <br>
В таких БД записи хранятся в парах «ключ-значение», где ключ выступает уникальным идентификатором. Ключи и значения фиксируются в виде простой или составной информации.<br>
Эти хранилища максимально быстро реагируют на запросы информации и прекрасно масштабируются. Key-value СУБД часто используют для систем, в которых скорость — это приоритет, а данные не слишком сложные. Например, для хранения кэша данных, онлайн-списков, обработки истечения срока действия, разделения сеансов, построения рейтинга и прочих задач. <br>
Яркий пример key-value store БД — Redis. Ей пользуются Airbnb, Slack, Twitter и Uber. Система целиком работает в оперативной памяти, что позволяет информации считываться и записываться намного быстрее, чем даже на очень шустрые твердотельные накопители.

2. __Колоночные базы данных (column family store).__<br>
У этих БД есть свои столбцы и строки, но информация записывается в колонки. Колонки между собой не связаны, поэтому удаление или добавление новых свойств не затрагивает остальную систему. Отсутствие заранее заданной схемы позволяет хранить в этих NoSQL-базах записи без чёткой структуры.<br>
В традиционной СУБД при выполнении запроса сканируется вся таблица, а информация из всей строки извлекается целиком. В колоночных БД выгружаются только необходимые значения, поскольку поиск ведётся по отдельным столбцам. Такой подход колоночных NoSQL баз к хранению информации позволяет быстро получать данные из больших таблиц для анализа. А возможность сильного сжатия данных экономит много места на диске.<br>
В этой категории существуют базы ClickHouse, Vertica, Cassandra и другие. Netflix, например, в том числе использует хранилище Cassandra: база легко масштабируется и у неё нет единых точек отказа.

3. __Документоориентированные базы данных (Document-oriented store).__ <br>
В БД этого типа данные записываются в документы и хранятся в формате, подобном JSON. Таким хранилищам свойственны иерархичность (документы складываются в коллекции, а коллекции группируются логически) и гибкость (значения, свойства и их структура может меняться в процессе разработки).<br>
Document-oriented-модель хороша в проектах, где нужно обрабатывать большой объём данных без чёткой структуры, а также для работы со множеством уникальных документов, которые со временем требуют изменений. Например, для каталогов товаров, соцсетей, платформ с блогами и видео, геоаналитики и в других сферах.<br>
Классический пример такой нереляционной СУБД — MongoDB.

4. __Графовые базы данных (graph store).__ <br>
Этот тип БД, основанный на топографической структуре сети, используется для выполнения задач, ориентированных на связи: для алгоритмов рекомендаций контента, социальных сетей, обнаружения случаев сетевого мошенничества. <br>
К графовым относятся базы данных Neo4j, OrientDB.

Для различных потребностей используются разные хранилища данных. И NoSQL не заменяет другие СУБД.

![001](/IntroCourseOnBigData/Pictures/001_016.PNG)

Источник: [BigData: Issues, Challenges, Technologies and Methods](https://www.researchgate.net/publication/315670334_BigData_Issues_Challenges_Technologies_and_Methods)

Стоит отметить, что NoSQL — неудачное имя для СУБД, так как большинство из них поддерживает SQL, а также существует реляционная (малоизвестная) СУБД, которая называется так же.

[Содержание](#содержание)
<hr>

## Форматы хранения данных

Все форматы файлов (включая и форматы для хранения текстовых документов в файлах) можно подразделить на бинарные и текстовые. 

Текстовый формат файла — это формат, основанный на plain text. Вся информация представлена в виде текста. В текстовом формате можно представить любую информацию, но её нужно закодировать в текстовый вид. Особенно популярны текстовые форматы, разумеется, для текстовых документов. 

Пример: txt. 

Но текстовый формат используется также для csv, xml, html и так далее.

Формат файла, не основанный на plain text, называется бинарным (от binary — «двоичный», поскольку в нём может использоваться любая последовательность двоичных данных). 

Например, офисный пакет Microsoft Office хранит документы, как правило, в файлах бинарных форматов.

У бинарных файлов есть преимущества перед текстовыми — в них можно реализовать следующий функционал:
1. Более быстрое время чтения.
2. Более быстрое время записи.
3. Разделяемые файлы.
4. Поддержка эволюции схем.
5. Расширенная поддержка сжатия.

Чтобы ускорить обработку данных, создавались форматы: Avro, Parquet, ORC и другие.

Время поиска, чтения и записи — часто узкое горлышко при работе с данными. Эти проблемы усугубляются трудностями в управлении большими наборами данных. Обработка больших данных увеличивает нагрузку на подсистему хранения — HDFS хранит данные избыточно для достижения отказоустойчивости. Кроме дисков, нагружаются процессор, сеть, система ввода-вывода и так далее. 

По мере роста объёма данных увеличивается и стоимость их обработки и хранения.

Отличия форматов:
1. Avro — формат хранения по строкам, Parquet — хранение по столбцам.
2. Parquet лучше подходит для аналитических запросов, то есть операции чтения и запрос данных гораздо эффективнее, чем запись. Операции записи эффективнее в Avro.
3. Avro более зрело работает с эволюцией схем. Parquet поддерживает только добавление схемы, а в Avro реализована многофункциональная эволюция, то есть добавление или изменение столбцов.
4. Parquet идеально подходит для запроса подмножества столбцов в многоколоночной таблице. Avro — для операций ETL, где мы запрашиваем все столбцы.
5. Parquet лучше хранит вложенные данные, чем ORC.
6. ORC лучше приспособлен к проталкиванию предикатов (predicate pushdown).
7. ORC поддерживает свойства ACID.
8. ORC лучше сжимает данные.

[Содержание](#содержание)
<hr>

## Выводы

На этой лекции мы познакомились с несколькими определениями обширного термина «Big Data», с его назначением и краткой историей. Узнали, что масштабирование данных бывает вертикальным и горизонтальным. Рассмотрели новый тип СУБД NoSQL, выявили его преимущества и недостатки в сравнении с реляционными базами данных. Эта лекция станет нашим мостиком к более глубокому изучению Big Data.

[Содержание](#содержание)
<hr>

## Что можно почитать ещё?

Introducing Data Science / Davy Cielen, Arno D. B. Meysman, Mohamed Ali

## Вопросы к лекции

+ У вас 5 ТБ данных, необходимость аналитики — 1 год. Является ли ваша работа с этими данными Big Data?
+ Какое масштабирование вы посоветуете дата-центру при условии, что вся свободная площадь для серверов уже занята?
+ Вопрос для самостоятельного изучения: всегда ли БД ключ-значение — это хэш-таблица?
+ Что такое NameNode и при чём тут сердцебиение?

[Содержание](#содержание)
<hr>

## Используемая литература
1. [Журнал Nature, выпуск от 4 сентября 2008](https://www.nature.com/nature/volumes/455/issues/7209)
2. [Большие данные — Википедия](https://ru.wikipedia.org/wiki/%D0%91%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D0%B5_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5)
3. [Big Data Technology that is used at CERN for Data Analysis - Aalpha](https://www.aalpha.net/articles/big-data-technology-that-is-used-at-cern-for-data-analysis/)
4. [Biggest social media platforms 2023 | Statista](https://www.statista.com/statistics/272014/global-social-networks-ranked-by-number-of-users/)
5. [[Best of 2019] The most popular social media networks each year, gloriously animated](https://thenextweb.com/tech/2019/06/11/most-popular-social-media-networks-year-animated/)
6. [Great Power, Great Responsibility: The 2018 Big Data & AI Landscape – Matt Turck](https://mattturck.com/bigdata2018/)
7. [Gartner Hype Cycle Research Methodology](https://mattturck.com/bigdata2018/)
8. [Understanding Gartner’s Hype Cycles](https://www.gartner.com/en/documents/3887767)
9. [Прошлое роста производительности: конец гонки частот, многоядерность и почему прогресс увяз на одном месте](https://habr.com/en/company/intel/blog/174719/)
10. [Быстрый старт в распределенные вычисления: 7 фундаментальных концепций](https://proglib.io/p/bystryy-start-v-raspredelennye-vychisleniya-7-fundamentalnyh-koncepciy-2022-08-24)

[Содержание](#содержание)
<hr>

# SQL и BigData

## Введение 2

На прошлой лекции мы узнали, что скрывается под термином «Big Data» и откуда он взялся. А также выяснили, что распределённые вычисления — основной способ обработки большого объёма данных.

Сегодня мы будем изучать основные инструменты для работы с большими данными. Это обзорная лекция, так что мы не будем глубоко погружаться в архитектуру инструментов и не будем изучать их все. Постараемся охватить нужный нам минимум: разберёмся, какие популярные инструменты бывают, для каких задач их используют и чем они отличаются.

На этой лекции вы узнаете:
+ Что такое Hadoop.
+ Какие инструменты и фреймворки использовать, если знаешь только SQL.

[Содержание](#содержание)
<hr>

## Термины, используемые в лекции 2

__Open source__ (открытое программное обеспечение) — ПО с открытым исходным кодом.

__Фонд Apache Software Foundation (ASF)__ — некоммерческая организация, которая разрабатывает открытый исходный код ПО под лицензией Apache (разрешение на изменение и распространение кода в любой форме), в том числе известного Apache HTTP Server веб-сервера.

__Java__ – строго типизированный объектно-ориентированный язык программирования общего назначения, разработанный компанией Sun Microsystems.

__Кластер__ – группа компьютеров, объединённых высокоскоростными каналами связи, представляющая с точки зрения пользователя единый аппаратный ресурс.

[Содержание](#содержание)
<hr>

## Экосистема Hadoop

![001](/IntroCourseOnBigData/Pictures/001_025.PNG)

Исторически так сложилось, что Hadoop — один из основных инструментов для анализа и обработки больших данных. Это одно из первых, универсальных и быстрых решений для распределённой работы с большими данными.

__Hadoop или экосистема Hadoop__ — это набор инструментов для построения системы работы с большими данными. Предназначен для сбора, хранения и распределённой обработки сотен терабайт информации, которая поступает непрерывным потоком.

__Hadoop__ — это open source продукт (проект фонда Apache Software Foundation), который можно модифицировать и использовать бесплатно. Он разработан на Java в рамках вычислительной парадигмы MapReduce, согласно которой приложение разделяется на большое количество одинаковых элементарных заданий, выполняемых на узлах кластера и естественным образом сводимых в конечный результат.

Всё началось с того, что Google с 2003 по 2006 выпустил три исследовательские работы. Эти работы навсегда изменили индустрию Big Data:
1. [The Google File System](https://dl.acm.org/doi/abs/10.1145/945445.945450) — распределённая файловая система, созданная компанией Google в 2000 году для своих внутренних потребностей.
2. [MapReduce: Simplified Data Processing on Large Clusters](https://dl.acm.org/doi/abs/10.1145/1327452.1327492) — вычислительная парадигма MapReduce.
3. [Bigtable: A Distributed Storage System for Structured Data](https://dl.acm.org/doi/abs/10.1145/1365815.1365816) — база данных на основе Google File System (GFS).

Все эти исследования помогали Google решать проблемы больших данных. Ведь с 2000 года по 2006 год объём данных у молодой растущей компании вырос в 26 раз (c миллионов до триллионов сайтов). Такой объём и сейчас сложно обработать, а в 2000-х это было в разы сложнее и дороже. И пусть даже эти работы оказали решающее влияние на появление Hadoop, Google к этому появлению отношения не имел, поскольку хранил свой исходный код закрытым.

![001](/IntroCourseOnBigData/Pictures/001_017.PNG)

Источник: [Hadoop: Toddler Talk Provides Big Data Name](https://www.cnbc.com/id/100769719)

Разработка Hadoop была инициирована в начале 2005 года Дугом Каттингом, сотрудником Yahoo, для проекта Nutch, идейной основой которой стали данные публикации сотрудников Google. Дуг Каттинг также разрабатывал поисковый движок для распределённого хранилища.

Проект начался с двух ключевых компонентов: распределённой файловой системы Hadoop (HDFS) и реализации фреймворка MapReduce. В отличие от Google, компания Yahoo решила открыть исходный код проекта в рамках Apache Software Foundation. Тем самым они пригласили остальные ведущие компании к его использованию и участию в развитии. 

После этого примерно к 2014 году Hadoop стал неотъемлемой частью технологий и фреймворков для работы с большими данными, включая различные направления, такие как подготовку и анализ данных, а также аналитические системы на базе алгоритмов машинного обучения.

В итоге с помощью этих инструментов для распределённого хранения и распределённых вычислений были решены две глобальные проблемы:
1. Как разместить сотни петабайт данных на тысячах дисков, установленных в более, чем тысяче машин, без простоя, потери информации и с сохранением её постоянной доступности?
2. Как распараллелить вычисление эффективным и отказоустойчивым способом для обработки всех этих данных на всех машинах?

![001](/IntroCourseOnBigData/Pictures/001_026.PNG)

Hadoop содержит четыре основных компонента или модуля (подробнее мы обсудим их позже):
1. __Hadoop Common__ — набор инструментов, необходимых в операционных системах пользователя (Windows, Unix или других), которые используются для создания инфраструктуры и работы с файлами. По сути, это управляющая система для остальных модулей и связи с дополнительными инструментами.
2. __HDFS (Hadoop Distributed File System)__ — распределённая файловая система для хранения данных на различных серверах. В неё встроена система дублирования данных, чтобы обеспечить их надёжность и сохранность даже при отказе отдельных серверов.
3. __YARN (Yet Another Resource Negotiator)__ — система управления кластером Hadoop (набор серверов), которая позволяет приложениям использовать вычислительные мощности.
4. __Hadoop MapReduce__ — платформа, отвечающая за MapReduce-вычисления. Также в системе Hadoop есть многочисленные дополнительные компоненты, например: Hive, Hbase, Cassandra, Pig, Flume, Zookeeper, Mahout, Sqoop, Oozie, Azkaban и другие. Самые популярные и используемые инструменты мы также изучим и рассмотрим подробнее.

_🔥 Стоит помнить, что Hadoop — это не один инструмент, а большой набор программного обеспечения с открытым исходным кодом, который в определённой степени интегрируется друг с другом и имеет несколько общих библиотек._

Мы уже знаем, что Google и Yahoo использовали Hadoop для поисковых машин. А также, что с помощью Hadoop мы можем обрабатывать практически любые существующие объёмы данных. Соответственно, придумать кейсы для использования этого инструмента несложно — нужно просто взять компанию, у которой много клиентов / данных.

Возможность обрабатывать больше данных позволяет повышать прибыль компании. 

Рассмотрим пару кейсов.

![001](/IntroCourseOnBigData/Pictures/001_027.PNG)

1. __Ритейлеры (магазины)__ — сбор данных о продажах и транзакциях, поведении покупателей на сайте, информации из соцсетей и с других ресурсов, финансовой информации, отчётности об ассортименте и складских остатках.<br>
Зная, как ведут себя клиенты, можно делать персональные предложения и акции, предлагать востребованные товары, разрабатывать программы лояльности, повышать продажи.<br>
Например, сети Walmart (20 000 магазинов в 28 странах) приходится каждый час обрабатывать 2,5 петабайт данных. Ритейлер получает информацию из 200 источников — это метрологические и экономические данные, данные Nielsen, телекоммуникаций, соцсетей, даже цены на газ и местные новости.<br>
Walmart каждый час обрабатывает около 25 000 запросов, 90% которых анализируется в течение 2 секунд.<br>
В Х5 Retail Group (более 15 000 магазинов) развёрнута платформа больших данных из 270 серверов (ядром выступает кластер Hadoop объёмом 4 петабайта данных), к которой подключены 70 источников. Всё это для того, чтобы максимально эффективно взаимодействовать с покупателем, строить для него персонализированные сервисы, прогнозировать его интересы, анализировать изменения потребностей.

![001](/IntroCourseOnBigData/Pictures/001_028.PNG)

2. __Финансовые организации__, в том числе банки, — анализ финансовой информации и рисков, выявление мошеннических действий и разработка защиты от них. Банки работают с большими объёмами данных о клиентах и транзакциях, их анализ помогает предсказывать количество посетителей в отделениях, остатки средств в банкоматах, приток и отток корпоративных клиентов.<br>
По состоянию на май 2018 года (более свежей информации нет), Сбербанк хранит и обрабатывает следующий объём информации:
+ 2 петабайта — общий объём данных в кластере;
+ 10 петабайт — плановый рост объёма данных в течение 2018 года;
+ 15,5 терабайт в сутки — объём ежедневного инкремента данных по текущим источникам;
+ 2000−5000 транзакций содержится в потоке в секунду;
+ 170 узлов кластера задействовано для обработки поступающего объёма;
+ 400 параллельных заданий по загрузке данных;
+ 200 терабайт — объём ежесуточно обновляемой информации в репликах систем-источников.
3. Многие другие сферы от интернета вещей до поиска месторождений.

![001](/IntroCourseOnBigData/Pictures/001_018.PNG)

В Сбере за четыре года объём данных вырос в 10 раз и составляет около 100 петабайт.

С Hadoop мы познакомились, но может возникнуть вопрос «зачем?». Hadoop — одно из решений для хранения и анализа больших данных. Его используют Google, Amazon, Facebook, Twitter, eBay, Sber, Beeline, МТС, многие другие гиганты рынка и не только. При этом технология подходит для любого бизнеса, работающего с большими объёмами данных, оптимизирована для работы на виртуальных машинах, удобно масштабируется.

Аналитик, работая с большими данными, так или иначе, столкнётся с экосистемой Hadoop. Аналитики Big Data обычно работают с ограниченным набором инструментов из экосистемы, но знание принципов работы базовых технологий Big Data позволит максимально эффективно использовать эти инструменты в работе. Эти знания позволят получить гораздо больший вес в глазах нанимателей и продвинуться по карьерной лестнице.

[Содержание](#содержание)
<hr>

## Основные компоненты
Выше были перечислены базовые компоненты Hadoop. Ниже мы обсудим некоторые из них подробнее, так как они базовые и встречаются часто. Обычно именно с ними сравниваются все новые разработки.

### MapReduce

__MapReduce__ — это модель распределённой обработки данных. Как мы уже знаем, она была предложена компанией Google для обработки больших объёмов данных на компьютерных кластерах.

MapReduce появился в связи с тем, что данные недостаточно просто хранить, из них нужно извлекать полезную информацию. 

![001](/IntroCourseOnBigData/Pictures/001_019.PNG)

Источник: [Big Data - Buzz Words: What is MapReduce - Day 7 of 21](https://blog.sqlauthority.com/2013/10/09/big-data-buzz-words-what-is-mapreduce-day-7-of-21/)

MapReduce предполагает, что данные организованы в виде некоторых записей.

Обработка данных происходит в 3 стадии:
1. Стадия __Map__ — данные предобрабатываются при помощи функции map(), которую определяет пользователь. Работа стадии заключается в предобработке и фильтрации данных. Она похожа на операцию map в функциональных языках программирования — пользовательская функция применяется к каждой входной записи.<br>
Функция map(), применённая к одной входной записи, выдаёт множество пар ключ-значение. Множество — то есть может выдать только одну запись, может не выдать ничего, а может выдать несколько пар ключ-значение.
2. Стадия __Shuffle__ проходит незаметно для пользователя. В этой стадии вывод функции map «разбирается по корзинам» — каждая корзина соответствует одному ключу вывода стадии map. В дальнейшем эти корзины послужат входом для reduce.
3. Стадия __Reduce__ — каждая «корзина» со значениями, сформированная на стадии shuffle, попадает на вход функции reduce().<br>
Функция reduce задаётся пользователем и вычисляет финальный результат для отдельной «корзины». Множество всех значений, возвращённых функцией reduce(), — этой финальный результат MapReduce-задачи.

Несколько фактов про MapReduce:
1. Все запуски функции map работают независимо и могут работать параллельно, в том числе на разных машинах кластера.
2. Все запуски функции reduce работают независимо и могут работать параллельно, в том числе на разных машинах кластера.
3. Shuffle внутри себя представляет параллельную сортировку, поэтому также может работать на разных машинах кластера.
4. MapReduce — это всегда полное сканирование данных, никаких индексов нет.

Это значит, что MapReduce плохо применим, когда ответ требуется очень быстро.

_💡 Первые три факта соответствуют принципам горизонтальной масштабируемости, которые мы проходили в первой лекции._

Главное отличие MapReduce от большинства других инструментов обработки данных в том, что он регулярно обращается к диску, ведь именно там сохраняются промежуточные и финальные итоги вычислений.

Таким образом, модель функционирует с задержками, причём эти задержки ограничивают применение MapReduce в целях обработки потоковых данных и решения Machine learning-задач.

MapReduce сейчас редко используется из-за невысокой производительности и повышенной сложности написания кода. Но всё же для некоторых простых задач, не требующий высокой производительности, MapReduce остаётся надёжным и более дешёвым инструментом, так как используется память диска, а не более дорогая оперативная.

[Содержание](#содержание)
<hr>

### YARN
__YARN (Yet Another Resource Negotiator — «ещё один ресурсный посредник»)__ — модуль, отвечающий за управление ресурсами кластеров и планирование заданий.

Или планировщик ресурсов, абстрагирующий все вычислительные ресурсы кластера и управляющий их предоставлением приложениям распределённой обработки.

MapReduce-программы и любые другие распределённые приложения с помощью YARN получают ресурсы для вычислений: YARN выполняет роль посредника между аппаратными ресурсами и приложениями. YARN обеспечивает возможность параллельного выполнения нескольких различных задач в рамках кластера и их изоляцию.

_Из названия понятно, что есть и другие менеджеры ресурсов, в том числе и в экосистеме Hadoop, но YARN — базовый._

[Содержание](#содержание)
<hr>

###  HDFS
__HDFS (Hadoop Distributed File System)__ — распределённая файловая система, предназначенная для хранения данных больших размеров, которые поблочно разделены между узлами вычислительного кластера.

Свойства файловой системы HDFS:
1. __Механизм репликации__ — файловая система Hadoop предназначена для хранения больших данных, распределённых по нескольким узлам кластера.<br>
Чтобы избежать потери данных при сбое какого-либо из узлов, в HDFS предусмотрена репликация данных, которая позволяет копировать данные между всеми узлами вычислительного кластера. Таким образом, выход из строя одного или нескольких узлов не повлечёт за собой потерю данных.
2. __Блоки данных__ — приложения, которые совместимы с HDFS, работают с большими наборами данных и, как правило, в распределенной среде. Эти приложения записывают свои данные только один раз, но читать эти данные могут несколько раз и требуют, чтобы чтения выполнялись со скоростью потоковой передачи (непрерывно). Для этого каждый файл HDFS разбивается на блоки, каждый из которых находится на отдельном узле кластера. Размер каждого такого блока составляет 64 МБ.
3. __Иерархическая организация файлов__ — пользователи или приложения могут создавать каталоги, хранить и удалять файлы в этих каталогах, а также переименовывать файлы. HDFS не поддерживает жёсткие ссылки (составляющая файла, описывающая его элемент каталога).
4. __Конвейерная репликация__ — клиент постоянно записывает данные в локальный файл. Как только локальный файл накапливает полный блок данных, клиент извлекает список узлов данных из узла имён (узел, отвечающий за репликацию). Этот список содержит узлы данных (data nodes), в которых будет храниться реплика (копия) этого блока. Затем клиент помещает блок данных в первый узел данных, который начинает получать данные порциями по 4KB и записывать их в свой локальный репозиторий.<br>
После этого данные передаются во второй узел данных, который делает то же самое (записывает их в свой репозиторий) и передаёт дальше по списку. Таким образом, данные передаются от одного узла данных к следующему, как по конвейеру.

![001](/IntroCourseOnBigData/Pictures/001_020.PNG)

Источник: [To SQL or NoSQL? That’s the database question | Ars Technica](Источник: To SQL or NoSQL? That’s the database question | Ars Technica)

HDFS предусматривает наличие центрального узла имён (NameNode), хранящего метаданные файловой системы и метаинформацию о распределении блоков, и серии узлов данных (DataNodes), непосредственно хранящих блоки файлов.

Узел имён отвечает за обработку операций уровня файлов и каталогов — открытие и закрытие файлов, манипуляция с каталогами. Узлы данных непосредственно отрабатывают операции по записи и чтению данных. Узел имён и узлы данных снабжаются веб-серверами, отображающими текущий статус узлов и позволяющими просматривать содержимое файловой системы. Административные функции доступны из интерфейса командной строки.

__HDFS__ — неотъемлемая часть Hadoop, однако Hadoop поддерживает работу и с другими распределёнными файловыми системами без использования HDFS.

Поддержка Amazon S3 и CloudStore реализована в основном дистрибутиве. С другой стороны, HDFS может использоваться не только для запуска MapReduce-заданий, но и как распределённая файловая система общего назначения, в частности, поверх неё реализована распределённая NoSQL СУБД Apache HBase, в её среде работает масштабируемая система машинного обучения Apache Mahout.

NameNode принимает все решения относительно репликации блоков. Он периодически получает Heartbeat и Blockreport от каждого из DataNodes в кластере. Получение Heartbeat подразумевает, что DataNode функционирует должным образом. Blockreport содержит список всех блоков в DataNode. При обнаружении NameNode-сервером отказа одного из DataNode-серверов (отсутствие heartbeat-сообщений от него), запускается механизм репликации данных.<br>
Аналогичные действия производятся в случае повреждении реплик или в случае увеличения количества реплик, присущих каждому блоку.<br>

Пространство имён HDFS хранится в NameNode. NameNode использует журнал транзакций, называемый EditLog, для постоянной записи каждого изменения, которое происходит с метаданными файловой системы. Например, создание нового файла в HDFS заставляет NameNode вставить запись в EditLog, указывающую на это.<br>
Аналогично изменение коэффициента репликации файла приводит к вставке новой записи в EditLog. NameNode использует файл в своей локальной файловой системе ОС для хранения EditLog. Всё пространство имён файловой системы, включая отображение блоков в файлы и свойства файловой системы, хранится в файле с именем FsImage. FsImage также сохраняется в виде файла в локальной файловой системе NameNode.

![001](/IntroCourseOnBigData/Pictures/001_030.PNG)

HDFS, как и любая другая файловая система, имеет набор команд (похожа на UNIX):

Команда<br>файловой<br>системы<br>(dfs) | Краткое описание
---|---
-rm | Удаление файла или каталога/директории
-ls | Вывод содержимого каталогов/директории и информации о файлах
-mkdir | Создание нового каталога/директории
-cat | Считывание данных из файла и вывод содержимого
-rmdir | Удаление каталога/директории
-put | Перемещение файла или каталога директории из локальной системы в папку HDFS на кластере
-rmr | Удаление файла или каталога/директории рекурсивно (включая все поддиректории и файлы в них)
-get | Перемещение файла из кластера HDFS в локальную систему
-count | Вывод информации о количестве директорий и файлов в каталоге и размере самого каталога
-df | Вывод информации о размере директории и объёме свободного места
-getmerge | Объединение файлов в HDFS
-chmod | Изменение прав доступа к файлу или директории
-copyToLocal | Перемещение файла из кластера HDFS в локальную систему (аналогична команде -get)
-stat | Вывод по формату статистики о файле или директории (размер, тип, владелец, уровень репликации, дата создания и так далее)
-head | Вывод первого килобайта данных
-usage | Информация о команде
-chown | Изменение владельца и/или группы для указанных файлов

Пример: hdfs dfs -ls / — для вывода списка файлов в корневой директории.

[Содержание](#содержание)
<hr>

## Другие инструменты Hadoop

![001](/IntroCourseOnBigData/Pictures/001_029.PNG)

К экосистеме Hadoop принадлежит множество программ, модулей, компонент. При этом под «принадлежностью» к экосистеме может подразумеваться как созданные на основе Hadoop программы, так и программы, имеющие с ним полную интеграцию, но при этом независимые от него.

Часть из них встречаются редко, часть практически повсеместно. В этой лекции постараемся осветить самые популярные инструменты.

Все компоненты Hadoop можно разделить на несколько типов (моментами весьма условно):
+ __Движки__ — модули обработки данных. Типичный пример — MapReduce. Также существуют Spark и Tez.
+ __SQL-ориентированные инструменты__ — используют SQL-синтаксис (чаще всего урезанный) для управления данными. Примеры — Hive, Impala, Shark, Spark SQL, Drill.
+ __Машинное обучение__ — утилиты для обучения и применения моделей машинного обучения. Примеры — Spark MLLib, Mahout.
+ __Стриминг__ — потоковая обработка и сбор данных. Примеры — Kafka, Flink, Spark Streaming, Storm
+ __Прочее__. БД — HBase, копирование данных из СУБД — Sqoop, планировщики — Oozie, Pig и многое другое.

Выделим самые известные и популярные (кроме SQL-ориентированных инструментов, о них позже):
+ Apache Spark — это мощный движок с открытым исходным кодом, построенный для скорости, простого использования, сложной аналитики.<br>
В нём есть API на Java, Scala, Python, R и SQL.<br>
Spark запускает программы до 100 раз быстрее, чем Hadoop MapReduce в памяти или в 10 раз быстрее на диске. Его можно использовать для построения приложений данных как библиотеки или для выполнения интерактивного специального анализа данных.<br>
Spark включает в себя множество библиотек для работы с помощью SQL с датафреймами и датасетами, MLlib для машинного обучения, GraphX для работы с графами и Spark Streaming для обработки данных в режиме реального времени. Вы можете комбинировать эти библиотеки в одном приложении.<br>
Кроме того, Spark может работать локально, на Hadoop, Apache Mesos, автономно или в облаке. Он может получить доступ к различным источникам данных, включая HDFS, Apache Cassandra, Apache HBase и S3.
+ __Apache Cassandra__ — децентрализованная, отказоустойчивая и надёжная база данных «ключ-значение». Хранилище само позаботится о проблемах наличия единой точки отказа, отказа серверов и о распределении данных между узлами кластера.<br>
Под надёжностью понимается итоговая согласованность данных с возможностью установки уровня согласования данных каждого запроса.<br>
Cassandra имеет ACID-поддержку транзакций (легковесную, на уровне одной записи) и вторичную индексацию, а также больше ориентирована на запись, чем на чтение данных.
+ __HBase__ — это NoSQL, распределённая база данных, написанная на JAVA. Она разработана как часть проекта Hadoop и запускается на кластере HDFS. Обеспечивает отказоустойчивый способ хранения больших объёмов разреженных данных.<br>
HBase линейно масштабируется для обработки огромных наборов данных с миллиардами строк и миллионами столбцов и легко объединяет источники данных, которые используют множество различных структур и схем.<br>
Эта NoSQL СУБД считается более подходящей для произвольного доступа к данным в виде множества согласованных операций чтения. Кроме того, она позволяет работать с большими данными как в поточном, так и в пакетном режиме, в том числе используя преимущества вычислительной модели
MapReduce.
+ Apache Kafka — распределённая система обмена сообщениями между серверными приложениями в режиме реального времени. Благодаря высокой пропускной способности, масштабируемости и надёжности
применяется для работы с большими объёмами данных.<br>
Большинство из этих инструментов требует знания дополнительного языка программирования либо специального набора команд, что повышает порог входа.<br>
Поэтому мы рассмотрим только те инструменты, которые не требуют навыков, кроме SQL.

__💡 Забавный факт.__
_В экосистеме Hadoop на логотипах проектов много животных. Из-за этого распределённую базу данных для синхронизации модулей назвали Apache Zookeeper (управляющий зоопарком)._

![001](/IntroCourseOnBigData/Pictures/001_021.PNG)

__Hadoop__ — проект верхнего уровня организации Apache Software Foundation, поэтому основным дистрибутивом и центральным репозиторием для всех наработок считается именно Apache Hadoop. Но некоторые компании собирают свои дистрибутивы, где уже есть предварительные конфигурации, настройки и нужный набор модулей.

Основные поставщики:
+ __Cloudera__. Ключевой продукт — CDH (Cloudera Distribution including Apache Hadoop) — связка популярных инструментов из инфраструктуры Hadoop под управлением Cloudera Manager. Менеджер берёт на себя ответственность за развёртывание кластера, установку всех компонентов и их дальнейший мониторинг. Кроме CDH, компания развивает и другие свои продукты, например, Impala. Отличительная черта Cloudera — стремление первыми предоставлять на рынке новые фичи, пусть даже и в ущерб стабильности.
+ __Hortonworks__. Так же, как и Cloudera, предоставляют единое решение в виде HDP (Hortonworks Data Platform). Отличительная черта — вместо разработки собственных продуктов они больше вкладывают в развитие продуктов Apache. Например, вместо Cloudera Manager они используют Apache Ambari, вместо Impala — дальше развивают Apache Hive.
+ __MapR__. В отличие от двух предыдущих компаний, основным источником доходов для которых, судя по всему, является консалтинг и партнёрские программы, MapR занимается непосредственно продажей своих наработок.<br>
Из плюсов: много оптимизаций, партнёрская программа с Amazon. Из минусов: в бесплатной версии (M3) урезан функционал. Кроме того, MapR — основной идеолог и главный разработчик Apache Drill.

[Содержание](#содержание)
<hr>

## SQL на больших данных

Несмотря на то, что Hadoop — это полноценная платформа для разработки любых приложений, чаще всего его используют в контексте хранения данных и конкретно SQL-решений. В этом нет ничего удивительного: большие объёмы данных почти всегда означают аналитику, а аналитику проще делать над табличными данными. К тому же специалиста, знающего SQL, легче найти.<br>
В инфраструктуре Hadoop есть несколько SQL-ориентированных инструментов. В этой части лекции мы с ними познакомимся. Используя эти инструменты, мы относительно легко и быстро, зная только SQL, сможем оперировать большими данными.<br>
Практически все инструменты ниже предоставляют ODBC-драйвера, позволяя подключить к ним такие инструменты, как Tableau или Microsoft Excel.

[Содержание](#содержание)
<hr>

### Apache Hive
Apache Hive — одна из самых первых СУБД Hadoop, популярная до сих пор. В качестве языка запросов использует HiveQL — урезанный диалект SQL, который всё же позволяет выполнять довольно сложные запросы над данными, хранимыми в HDFS. Это движок, который превращает SQL-запросы в джобы MapReduce, Spark или Tez. Хорош для обработки больших запросов и ETL, плох для обработки транзакций в реальном времени. <br>
Hive использует хранилище метаданных Metastore для матчинга сущностей SQL (база данных, таблица, колонки, строки, ячейки) с объектами, хранящимися в HDFS или S3. В качестве Metastore используется RDBMS вроде MySQL, PostgreSQL или Oracle.

![001](/IntroCourseOnBigData/Pictures/001_022.PNG)

Источник: [Hive data organization — Partitioning & Clustering](https://medium.com/nerd-for-tech/hive-data-organization-partitioning-clustering-3e14ef6ab121)

Таблицы создаются таким же образом, как в классических реляционных базах данных. Являются физическим представлением данных, хранящихся в директории внутри файловой системы:<br>
/user/hive/warehouse/mytable<br>
/user/hive/warehouse/mytable/dep_id=dep_id1=Moscow<br>
/user/hive/warehouse/mytable/dep_id=dep_id1/part-00000<br>
Сложные обработки, которые нельзя написать на SQL, можно реализовать через написание своих функций: User Defined Function (UDF), User Defined Aggregate Function (UDAF), User Defined Tabular Function (UDTF).

[Содержание](#содержание)
<hr>

### Apache Impala
Apache Impala — это механизм запросов SQL с открытым исходным кодом с массовым параллелизмом (MPP) для данных, хранящихся в компьютерном кластере, на котором запущен Apache Hadoop.<br>
Impala привносит в Hadoop технологию масштабируемых параллельных баз данных, позволяя пользователям решать проблемы с низкой задержкой SQL, запрашивает данные, хранящиеся в HDFS, не требуя перемещения или преобразования данных. Impala интегрирована с Hadoop. Использует те же метаданные, синтаксис SQL (Hive SQL), драйвер ODBC и пользовательский интерфейс, что и Apache Hive.<br>
Написана на C++/Java, очень быстрая. Общается с YARN через Llama.

[Содержание](#содержание)
<hr>

### Apache Drill
Apache Drill — распределённый механизм запросов SQL с низкой задержкой для больших наборов данных, включая структурированные и полуструктурированные / вложенные данные.<br>
Один запрос может объединять данные из нескольких хранилищ (HDFS, S3, RDBMs и других), выполняя оптимизацию, специфичную для каждого из них. Drill полностью поддерживает стандартный SQL. Работает независимо от Hadoop.

[Содержание](#содержание)
<hr>

### Presto / Trino
Presto — высокопроизводительный, распределённый SQL-обработчик запросов для больших данных. Его архитектура позволяет пользователям запрашивать различные источники данных, такие как Hadoop, AWS S3, Alluxio, MySQL, Cassandra, Kafka и MongoDB. Можно даже запрашивать данные из нескольких источников в рамках одного запроса. Presto — это управляемое сообществом ПО с открытым
исходным кодом, выпущенное под лицензией Apache. 

[Содержание](#содержание)
<hr>

### Apache Hue

HUE (Hadoop User Experience) – это open source веб-интерфейс для анализа данных.<br>
Выпускается под лицензией Apache. Принадлежит компании Cloudera. 

Аббревиатуру HUE можно перевести как «Хадупный пользовательский опыт».

![001](/IntroCourseOnBigData/Pictures/001_023.PNG)

[Содержание](#содержание)
<hr>

### Облака
Всё большей популярностью пользуются облачные решения, которые предоставляют простой, удобный и широкий функционал. Часть из них основана на Hadoop, часть использует другие решения, но всю настройку и масштабирование кластера сервис берёт на себя.

![001](/IntroCourseOnBigData/Pictures/001_024.PNG)

Источник: [Snowflake, Redshift, BigQuery, and Others: Cloud Data Warehouse Tools Compared](https://www.altexsoft.com/blog/snowflake-redshift-bigquery-data-warehouse-tools/)

[Содержание](#содержание)
<hr>

## Итог
Мы поближе познакомились с экосистемой Hadoop. Теперь знаем, какие есть инструменты и какие сложились практики работы с данными. Мы можем использовать эти знания, чтобы выбрать подходящие инструменты для задачи или оценить существующие, чтобы использовать их эффективнее.

## Домашнее задание

HDFS — базовая и повсеместно используемая файловая система в Hadoop. Поэтому важно уметь с ней работать. Задание на HDFS:
1. Скопируйте файл из одной директории в другую.
2. Посмотрите, какой уровень репликации у файла.
3. Измените уровень репликации.

HveQL:
1. Создайте таблицу.
2. Выполните запрос.

## Что можно почитать ещё?
1. [2003–2023: Краткая история Big Data / Хабр](https://habr.com/ru/company/ruvds/blog/702932/) — статья про историю появления Hadoop на русском.
2. Hadoop: The Definitive Guide by Tom White — всё о Hadoop.
3. [Hive LanguageManual](https://cwiki.apache.org/confluence/display/Hive/LanguageManual) — документация по HiveQL.

## Используемая литература
1. [Apache Hadoop](https://hadoop.apache.org/)
2. [Hadoop — Википедия](https://ru.wikipedia.org/wiki/Hadoop)
3. [Official Google Blog: We knew the web was big…](https://googleblog.blogspot.com/2008/07/we-knew-web-was-big.html)
4. [Зачем Big Data нужна ритейлу](https://e-pepper.ru/news/zachem-big-data-nuzhna-riteylu.html)
5. [Сбербанк нашел разработчиков супермаркета данных ](https://www.tadviser.ru/index.php/%D0%9F%D1%80%D0%BE%D0%B5%D0%BA%D1%82:%D0%A1%D0%B1%D0%B5%D1%80%D0%B1%D0%B0%D0%BD%D0%BA_%D0%A0%D0%A4_(BigData_%D0%BD%D0%B0_%D0%BE%D1%81%D0%BD%D0%BE%D0%B2%D0%B5_Apache_Hadoop))
6. [Big Data - Buzz Words: What is MapReduce - Day 7 of 21 - SQL Authority with Pinal Dave](https://blog.sqlauthority.com/2013/10/09/big-data-buzz-words-what-is-mapreduce-day-7-of-21/)
7. [Big Data от А до Я. Часть 1: Принципы работы с большими данными, парадигма MapReduce](https://habr.com/ru/post/267361/)
8. [Apache Impala](https://impala.apache.org/)
9. [Apache Hive](https://hive.apache.org/)
10. [Apache Drill](https://drill.apache.org/)
11. [«Супермаркет данных» в «Сбере»: единое окно для заказа данных с доставкой пользователю](https://cio.osp.ru/articles/240222-Supermarket-dannyh-v-Sbere-edinoe-okno-dlya-zakaza-dannyh-s-dostavkoy-polzovatelyu)
12. [HBase vs Cassandra - 8 Major Difference & Similarities in 2022 - DataFlair](https://data-flair.training/blogs/hbase-vs-cassandra/)

[Содержание](#содержание)
<hr>

